{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized data, with GA effect\n",
    "#data = pd.read_csv(\"esetSC2_normalized.csv\")\n",
    "\n",
    "# data here is normalized, and the GA effect is removed.\n",
    "data = pd.read_csv(\"esetSC2_remove_effect.csv\")\n",
    "\n",
    "# data information\n",
    "data_info = pd.read_csv('anoSC2_v20_nokey.csv')\n",
    "\n",
    "# GA information\n",
    "GA_info = pd.read_csv(\"allSamplesSC1and2.csv\")\n",
    "\n",
    "GA_infomation = GA_info.set_index(\"SampleID\")\n",
    "GA_infomation = GA_infomation.loc[data.columns]\n",
    "data_infomation = data_info.reset_index().set_index(\"SampleID\").drop(columns = 'index')\n",
    "data_infomation = data_infomation.loc[data.columns]\n",
    "data_infomation = data_infomation[(data_infomation['Group']=='Control') | (data_infomation['Group']=='sPTD')]\n",
    "data = data[data_infomation.index]\n",
    "data_copy = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SampleList_To_Group(sample_list, data_infomation = data_infomation):\n",
    "    control_sample = []\n",
    "    sPTD_sample = []\n",
    "    sample_group = []\n",
    "    for sample in sample_list:\n",
    "        group = data_infomation.loc[[sample]][['Group']].values[0][0]\n",
    "        if group == 'Control':\n",
    "            control_sample.append(sample)\n",
    "            sample_group.append('Control')\n",
    "        if group == 'sPTD':\n",
    "            sPTD_sample.append(sample)\n",
    "            sample_group.append('sPTD')\n",
    "    return sample_group, control_sample, sPTD_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = list(data.columns)\n",
    "sample_group, control_sample, sPTD_sample = SampleList_To_Group(sample_list)\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(data.transpose(), sample_group,test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Feature Selection: Choose genes with high t-test score in different GA and all GAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_sample = []\n",
    "sPTD_sample = []\n",
    "sapmles = list(xtrain.index)\n",
    "sample_group, control_sample, sPTD_sample = SampleList_To_Group(sapmles)\n",
    "sPTD_data = xtrain.transpose()[control_sample + sPTD_sample]\n",
    "df = sPTD_data\n",
    "df[['Control_mean', 'Control_std']] = df[control_sample].agg(['mean', 'std'], axis=1)\n",
    "df[['sPTD_mean', 'sPTD_std']] = df[sPTD_sample].agg(['mean', 'std'], axis=1)\n",
    "def welch_t_test(row):\n",
    "    return (\n",
    "        (row['Control_mean'] - row['sPTD_mean']) / \n",
    "        np.sqrt(row['Control_std']/len(control_sample) + row['sPTD_std']/len(sPTD_sample))\n",
    "    )\n",
    "df['similarity'] = df[['Control_mean', 'Control_std', 'sPTD_mean', 'sPTD_std']].apply(welch_t_test, axis=1)\n",
    "df['similarity_abs'] = abs(df['similarity'])\n",
    "df_sorted = df.sort_values('similarity_abs',ascending=False)\n",
    "data_infomation_train = data_infomation.loc[xtrain.index]\n",
    "GA_values = np.unique(data_infomation_train.loc[df_sorted.columns[:-5]][['GA']].values)\n",
    "GA_values = [x for x in GA_values if str(x) != 'nan']\n",
    "df_dict_GA = {}\n",
    "for key in GA_values:\n",
    "    GA_samples = data_infomation_train.loc[data_infomation_train['GA']==key].index\n",
    "    df_dict_GA[key] = GA_samples.tolist()   \n",
    "df  = df_sorted.drop(columns=['Control_mean', 'Control_std', 'sPTD_mean', 'sPTD_std', 'similarity','similarity_abs'])\n",
    "for key in df_dict_GA:\n",
    "    df_dict_GA[key] = df[df_dict_GA[key]]\n",
    "df_dict_GA=pickle.load(open('df_dict_GA_1.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_similarity = []\n",
    "for key in df_dict_GA:\n",
    "    df = df_dict_GA[key]\n",
    "    gene = df.loc[df[\"similarity_abs\"] >= 3].index.tolist()\n",
    "    gene_similarity = gene_similarity + gene\n",
    "gene = sPTD_data.loc[df_sorted[\"similarity_abs\"] >= 2].index.tolist()\n",
    "gene_similarity = gene_similarity + gene\n",
    "gene_similarity = np.unique(gene_similarity)\n",
    "xtrain = xtrain[gene_similarity]\n",
    "xtest = xtest[gene_similarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "def Cross_Validation(df = xtrain):\n",
    "    kf = KFold(n_splits=5)\n",
    "    train_set_list = []\n",
    "    validation_set_list = []\n",
    "    for train_set, validation_set in kf.split(df):\n",
    "        train_set = df.iloc[train_set]\n",
    "        validation_set = df.iloc[validation_set]\n",
    "        train_set_list.append(train_set)\n",
    "        validation_set_list.append(validation_set)\n",
    "    return train_set_list, validation_set_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def prediction_knn(features, df = xtrain, y = ytrain):\n",
    "    df = df[features]\n",
    "    total_error_ = []\n",
    "    train_set_list, validation_set_list = Cross_Validation(df)\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    for i in range(len(train_set_list)):\n",
    "        train = train_set_list[i]\n",
    "        test = validation_set_list[i]\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(train.index))\n",
    "        y_train = sample_group\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(test.index))\n",
    "        y_test = sample_group\n",
    "        clf.fit(train, y_train)\n",
    "        pred = clf.predict(test).tolist()\n",
    "        error = 0\n",
    "        for i in range(len(pred)):\n",
    "            if y_test[i] != pred[i]:\n",
    "                error += 1\n",
    "        total_error_.append(error)\n",
    "    total_error = np.sum(total_error_)\n",
    "    sample_number = df.shape[0]\n",
    "    error_rate =  total_error/sample_number\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148936170212766\n",
      "0.0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "rfe_lib = {}\n",
    "feature_lib = {}\n",
    "feature_number = xtrain.shape[0]\n",
    "df = xtrain\n",
    "for n_features_to_select in range(1,feature_number):\n",
    "    clf = SVC(kernel=\"linear\", C=1)\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe.fit(df, ytrain)\n",
    "    Features = df.columns[rfe.support_]\n",
    "    error_rate = prediction_knn(features = Features)\n",
    "    rfe_lib[n_features_to_select] = error_rate\n",
    "    feature_lib[n_features_to_select] = Features\n",
    "p1 = list(rfe_lib.keys())\n",
    "best_genes_numbers = p1.index(min(p1))+1\n",
    "genes = list(feature_lib[best_genes_numbers])\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "xtrain_FS = xtrain[genes]\n",
    "xtest_FS = xtest[genes]\n",
    "clf.fit(xtrain_FS, ytrain)\n",
    "knn_predict = clf.predict(xtest_FS)\n",
    "prediction = list(knn_predict)\n",
    "result = ytest\n",
    "error_num = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == result[i]:\n",
    "        pass\n",
    "    else:\n",
    "        error_num = error_num+1\n",
    "positive_number = 0        \n",
    "negative_number = 0\n",
    "TP_number = 0\n",
    "TN_number = 0\n",
    "for i in range(len(prediction)):\n",
    "    if result[i] == 'Control':\n",
    "        positive_number = positive_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TP_number = TP_number+1\n",
    "    if result[i] == 'sPTD':\n",
    "        negative_number = negative_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TN_number = TN_number+1\n",
    "TP_rate = TP_number/positive_number\n",
    "TN_rate = TN_number/negative_number\n",
    "print(TP_rate)\n",
    "print(TN_rate)\n",
    "print(error_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "def prediction_knn(features, df = xtrain, y = ytrain):\n",
    "    df = df[features]\n",
    "    total_error_ = []\n",
    "    train_set_list, validation_set_list = Cross_Validation(df)\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    for i in range(len(train_set_list)):\n",
    "        train = train_set_list[i]\n",
    "        test = validation_set_list[i]\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(train.index))\n",
    "        y_train = sample_group\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(test.index))\n",
    "        y_test = sample_group\n",
    "        clf.fit(train, y_train)\n",
    "        pred = clf.predict(test).tolist()\n",
    "        error = 0\n",
    "        for i in range(len(pred)):\n",
    "            if y_test[i] != pred[i]:\n",
    "                error += 1\n",
    "        total_error_.append(error)\n",
    "    total_error = np.sum(total_error_)\n",
    "    sample_number = df.shape[0]\n",
    "    error_rate =  total_error/sample_number\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148936170212766\n",
      "0.5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "rfe_lib = {}\n",
    "feature_lib = {}\n",
    "feature_number = xtrain.shape[0]\n",
    "df = xtrain\n",
    "for n_features_to_select in range(1,feature_number):\n",
    "    clf = ExtraTreesClassifier(n_estimators=100)\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe.fit(df, ytrain)\n",
    "    Features = df.columns[rfe.support_]\n",
    "    error_rate = prediction_knn(features = Features)\n",
    "    rfe_lib[n_features_to_select] = error_rate\n",
    "    feature_lib[n_features_to_select] = Features\n",
    "p1 = list(rfe_lib.keys())\n",
    "best_genes_numbers = p1.index(min(p1))+1\n",
    "genes = list(feature_lib[best_genes_numbers])\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "xtrain_FS = xtrain[genes]\n",
    "xtest_FS = xtest[genes]\n",
    "clf.fit(xtrain_FS, ytrain)\n",
    "knn_predict = clf.predict(xtest_FS)\n",
    "prediction = list(knn_predict)\n",
    "result = ytest\n",
    "error_num = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == result[i]:\n",
    "        pass\n",
    "    else:\n",
    "        error_num = error_num+1\n",
    "positive_number = 0        \n",
    "negative_number = 0\n",
    "TP_number = 0\n",
    "TN_number = 0\n",
    "for i in range(len(prediction)):\n",
    "    if result[i] == 'Control':\n",
    "        positive_number = positive_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TP_number = TP_number+1\n",
    "    if result[i] == 'sPTD':\n",
    "        negative_number = negative_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TN_number = TN_number+1\n",
    "TP_rate = TP_number/positive_number\n",
    "TN_rate = TN_number/negative_number\n",
    "print(TP_rate)\n",
    "print(TN_rate)\n",
    "print(error_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "def prediction_knn(features, df = xtrain, y = ytrain):\n",
    "    df = df[features]\n",
    "    total_error_ = []\n",
    "    train_set_list, validation_set_list = Cross_Validation(df)\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)\n",
    "    for i in range(len(train_set_list)):\n",
    "        train = train_set_list[i]\n",
    "        test = validation_set_list[i]\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(train.index))\n",
    "        y_train = sample_group\n",
    "        sample_group, control_sample, sPTD_sample = SampleList_To_Group(list(test.index))\n",
    "        y_test = sample_group\n",
    "        clf.fit(train, y_train)\n",
    "        pred = clf.predict(test).tolist()\n",
    "        error = 0\n",
    "        for i in range(len(pred)):\n",
    "            if y_test[i] != pred[i]:\n",
    "                error += 1\n",
    "        total_error_.append(error)\n",
    "    total_error = np.sum(total_error_)\n",
    "    sample_number = df.shape[0]\n",
    "    error_rate =  total_error/sample_number\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361702127659575\n",
      "0.25\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "rfe_lib = {}\n",
    "feature_lib = {}\n",
    "feature_number = xtrain.shape[0]\n",
    "df = xtrain\n",
    "for n_features_to_select in range(1,feature_number):\n",
    "    clf = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe.fit(df, ytrain)\n",
    "    Features = df.columns[rfe.support_]\n",
    "    error_rate = prediction_knn(features = Features)\n",
    "    rfe_lib[n_features_to_select] = error_rate\n",
    "    feature_lib[n_features_to_select] = Features\n",
    "p1 = list(rfe_lib.keys())\n",
    "best_genes_numbers = p1.index(min(p1))+1\n",
    "genes = list(feature_lib[best_genes_numbers])\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "xtrain_FS = xtrain[genes]\n",
    "xtest_FS = xtest[genes]\n",
    "clf.fit(xtrain_FS, ytrain)\n",
    "knn_predict = clf.predict(xtest_FS)\n",
    "prediction = list(knn_predict)\n",
    "result = ytest\n",
    "error_num = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == result[i]:\n",
    "        pass\n",
    "    else:\n",
    "        error_num = error_num+1\n",
    "positive_number = 0        \n",
    "negative_number = 0\n",
    "TP_number = 0\n",
    "TN_number = 0\n",
    "for i in range(len(prediction)):\n",
    "    if result[i] == 'Control':\n",
    "        positive_number = positive_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TP_number = TP_number+1\n",
    "    if result[i] == 'sPTD':\n",
    "        negative_number = negative_number+1\n",
    "        if prediction[i] == result[i]:\n",
    "            TN_number = TN_number+1\n",
    "TP_rate = TP_number/positive_number\n",
    "TN_rate = TN_number/negative_number\n",
    "print(TP_rate)\n",
    "print(TN_rate)\n",
    "print(error_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
